---
layout: post
title: 'Should AI Take the Wheel?'
categories: AI life-decisions philosophy
excerpt_separator: <!--excerpt_separator-->
---

When my wife asked, "_Which decisions should you **not** delegate to AI?_", I froze mid-thought.

<!--excerpt_separator-->

At that moment, it hit me just how much I'd already outsourced—maybe even too much. She noticed (quicker than I did!) that I'd become increasingly dependent on AI, whose capabilities seem to grow by the week.

It started innocently enough. Small questions like:

> What meal can I make with these leftovers?

quickly escalated to:

> Should we move to another city?

Before long, decisions I'd usually ponder through journaling, or with trusted friends, had slowly become quick prompts to ChatGPT, answered instantly. Convenience quietly replaced reflection.

It begs the question: when do we cross the line from helpful to dangerously passive?

## Better decisions

Recently, I chatted about this with a [friend](https://x.com/Aay17ush). We talked about how little practice we really get with life's biggest choices: leaving a job, ending a relationship, deciding to move abroad. These choices come up infrequently yet have massive stakes attached, no wonder we struggle with them.

From this perspective, AI seems almost irresistible. Trained on humanity’s collective experiences, less affected by the emotional blind spots that hinder our judgment,[^1] wouldn't AI naturally tend to make wiser, more objective choices?

## Cheat code to life

_Yet_, even if AI produces objectively better outcomes, could depending on it take away something vital?

It reminds me of using cheat codes in video games as a child (`IDDQD`, anyone?). At first, cheating felt amazing. Soon afterward, however, I noticed something unexpected—I wasn’t having any fun. The challenge vanished, the tension collapsed, and with them disappeared all the joy and meaning behind playing in the first place.

I wonder: Could over-depending on AI feel the same way, robbing me of life's struggles—the very struggles that I suspect build character, resilience, and empathy?

I've resorted to cheats in games when they became frustratingly hard or when low mood got the best of me, _even_ when I knew it would spoil the fun longer-term. If I can't resist that temptation in gaming, how can I resist the allure of AI making my life easier?

---

_But maybe_ the gaming analogy doesn't perfectly map onto real life. It’s worth exploring the limitations of this idea.

## Real life isn't a carefully crafted video game

Our daily challenges aren't necessarily meaningful or valuable. Many struggles aren't instructive—they're random, painful occurrences delivering little personal growth or satisfaction.

In these circumstances, reducing unnecessary trauma and harm isn't "cheating"; it's just common sense.

### Not all gain requires pain

And maybe I've overestimated the necessity of struggle and hardship for personal growth. Positive experiences like curiosity and creativity, can also shape who we become. Perhaps AI might help us learn and grow without unnecessarily painful detours.


### …but some gain still might?

Still, there's a risk: if we delegate _every_ challenging decision, we might lose the valuable tension that drives personal growth.

There's value in wrestling with uncertainty even when the AI reliably suggests _a_ good path. That tension carries meaning—or at the very least feels very human.

## Local maxima trap

_Further complicating things_, even if AI could perfectly optimize for our preferences, it might trap us in a 'local maximum'—offering instant relief while stalling long-term growth. Picture an AI that keeps you in barely tolerable relationships or jobs, preventing the discomfort that often sparks transformative change.[^2] In short, short-term comfort might lead to long-term stagnation, much like the marshmallow test suggests.

## Convenience vs. Agency

All these thoughts bring me back to larger questions of personal agency. As AI improves, will relying on it drain my sense of autonomy? Will life lose some deep, intangible spark if I delegate too many important decisions?

My current view: we will have to try and see. What comforts me a bit is reflecting on my life thus far. Despite thinking of myself as the _instant gratification monkey_, my life tells a different story—I actually go out of my comfort zone and do stuff despite the lure of The Algorithm.

So I expect AI to become more powerful, more useful, and I also feel confident that I'll notice if I start veering toward an unfulfilling, agency-lacking existence—and trust myself to course-correct.

I'd love to hear your thoughts, and I'm curious how future-me will reflect on another year of closer reliance on AI.

[^1]: To be clear, today's AIs carry _all the biases_ inherited from training data; the hope is that they balance each other out.

[^2]: Current AIs are good at surface-level optimization but may fail to suggest difficult-in-the-moment but ultimately enriching decisions. Future models could potentially integrate secondary- and tertiary-level consequences, vectorize your preferences and _your whole psyche_, and ultimately be able to make decisions that are _just good for you_. But that is post-singularity AI, firmly in Speculationland.