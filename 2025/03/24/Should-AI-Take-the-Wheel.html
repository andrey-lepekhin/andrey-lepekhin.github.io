<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <!--<title>Should AI Take the Wheel? &#8211; </title>--> <link rel="dns-prefetch" href="//maxcdn.bootstrapcdn.com"> <link rel="dns-prefetch" href="//cdnjs.cloudflare.com"> <meta name="viewport" content="width=device-width, initial-scale=1"> <!--<meta name="description" content="Thoughts on life improvement">--> <meta name="robots" content="all"> <meta name="author" content="Andrey Lepekhin"> <meta name="keywords" content="AI, life-decisions, philosophy"> <!--<link rel="canonical" href="https://www.lepekhin.com/2025/03/24/Should-AI-Take-the-Wheel">--> <link rel="alternate" type="application/rss+xml" title="RSS Feed for " href="/feed.xml" /> <!-- Custom CSS --> <link rel="stylesheet" href="/css/pixyll.css?202506232213" type="text/css"> <!-- Fonts --> <!--<link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>--> <!--<link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>--> <!--<script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"></script> <script> WebFont.load({ google: { families: ['Merriweather:900,900:italic,300,300:italic', 'Lato:900,300'] } }); </script> --> <!-- MathJax --> <!-- Verifications --> <!-- Begin Jekyll SEO tag v2.6.1 --> <title>Should AI Take the Wheel? | The Blog of Andrey Lepekhin</title> <meta name="generator" content="Jekyll v3.10.0" /> <meta property="og:title" content="Should AI Take the Wheel?" /> <meta name="author" content="Andrey Lepekhin" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="When my wife asked, “Which decisions should you not delegate to AI?”, I froze mid-thought." /> <meta property="og:description" content="When my wife asked, “Which decisions should you not delegate to AI?”, I froze mid-thought." /> <link rel="canonical" href="https://www.lepekhin.com/2025/03/24/Should-AI-Take-the-Wheel" /> <meta property="og:url" content="https://www.lepekhin.com/2025/03/24/Should-AI-Take-the-Wheel" /> <meta property="og:site_name" content="The Blog of Andrey Lepekhin" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-03-24T00:00:00+02:00" /> <script type="application/ld+json"> {"url":"https://www.lepekhin.com/2025/03/24/Should-AI-Take-the-Wheel","headline":"Should AI Take the Wheel?","dateModified":"2025-03-24T00:00:00+02:00","datePublished":"2025-03-24T00:00:00+02:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.lepekhin.com/2025/03/24/Should-AI-Take-the-Wheel"},"author":{"@type":"Person","name":"Andrey Lepekhin"},"description":"When my wife asked, “Which decisions should you not delegate to AI?”, I froze mid-thought.","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --> <!-- Twitter Card --> <meta name="twitter:card" content="summary" /> <meta name="twitter:title" content="Should AI Take the Wheel?" /> <meta name="twitter:description" content="When my wife asked, “Which decisions should you not delegate to AI?”, I froze mid-thought. " /> <meta name="twitter:url" content="https://www.lepekhin.com/2025/03/24/Should-AI-Take-the-Wheel" /> <!-- Icons --> <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png?v=47BwG2e8GN"> <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png?v=47BwG2e8GN"> <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png?v=47BwG2e8GN"> <link rel="manifest" href="/site.webmanifest?v=47BwG2e8GN"> <link rel="mask-icon" href="/safari-pinned-tab.svg?v=47BwG2e8GN" color="#5bbad5"> <link rel="shortcut icon" href="/favicon.ico?v=47BwG2e8GN"> <meta name="msapplication-TileColor" content="#2b5797"> <meta name="theme-color" content="#ffffff"> </head> <body class="site"> <div class="site-wrap"> <header class="site-header px2 px-responsive"> <div class="mt2 wrap"> <div class="measure"> <div class="site-nav site-index"><a href="https://www.lepekhin.com">Index</a></div> <nav class="site-nav"> <a href="/about">About me</a> </nav> <div class="clearfix"></div> </div> </div> </header> <div class="post p2 p-responsive wrap" role="main"> <div class="measure"> <div class="post-header mb2"> <h1>Should AI Take the Wheel?</h1> <span class="post-meta">Mar 24, 2025</span> <span class="post-meta small" title="Post tags" style="float:right; !important; font-style: normal; "> </span> <span class="post-meta small" title="Post categories" style="float:right; !important; font-style: normal; "><a href="https://www.lepekhin.com/category/AI" style="color: #7a7a7a !important; background-image: none;">AI</a>,&nbsp;<a href="https://www.lepekhin.com/category/life-decisions" style="color: #7a7a7a !important; background-image: none;">life-decisions</a>,&nbsp;<a href="https://www.lepekhin.com/category/philosophy" style="color: #7a7a7a !important; background-image: none;">philosophy</a> </span> <br> <span class="post-meta small" title="Estimated read time"> 5 minute read </span> </div> <article class="post-content"> <p>When my wife asked, “<em>Which decisions should you <strong>not</strong> delegate to AI?</em>”, I froze mid-thought.</p> <!--excerpt_separator--> <p>At that moment, it hit me just how much I’d already outsourced—maybe even too much. She noticed (quicker than I did!) that I’d become increasingly dependent on AI, whose capabilities seem to grow by the week.</p> <p>It started innocently enough. Small questions like:</p> <blockquote> <p>What meal can I make with these leftovers?</p> </blockquote> <p>quickly escalated to:</p> <blockquote> <p>Should we move to another city?</p> </blockquote> <p>Before long, decisions I’d usually ponder through journaling, or with trusted friends, had slowly become quick prompts to ChatGPT, answered instantly. Convenience quietly replaced reflection.</p> <p>It begs the question: when do we cross the line from helpful to dangerously passive?</p> <h2 id="better-decisions">Better decisions</h2> <p>Recently, I chatted about this with a <a href="https://x.com/Aay17ush">friend</a>. We talked about how little practice we really get with life’s biggest choices: leaving a job, ending a relationship, deciding to move abroad. These choices come up infrequently yet have massive stakes attached, no wonder we struggle with them.</p> <p>From this perspective, AI seems almost irresistible. Trained on humanity’s collective experiences, less affected by the emotional blind spots that hinder our judgment,<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> wouldn’t AI naturally tend to make wiser, more objective choices?</p> <h2 id="cheat-code-to-life">Cheat code to life</h2> <p><em>Yet</em>, even if AI produces objectively better outcomes, could depending on it take away something vital?</p> <p>It reminds me of using cheat codes in video games as a child (<code class="language-plaintext highlighter-rouge">IDDQD</code>, anyone?). At first, cheating felt amazing. Soon afterward, however, I noticed something unexpected—I wasn’t having any fun. The challenge vanished, the tension collapsed, and with them disappeared all the joy and meaning behind playing in the first place.</p> <p>I wonder: Could over-depending on AI feel the same way, robbing me of life’s struggles—the very struggles that I suspect build character, resilience, and empathy?</p> <p>I’ve resorted to cheats in games when they became frustratingly hard or when low mood got the best of me, <em>even</em> when I knew it would spoil the fun longer-term. If I can’t resist that temptation in gaming, how can I resist the allure of AI making my life easier?</p> <hr /> <p><em>But maybe</em> the gaming analogy doesn’t perfectly map onto real life. It’s worth exploring the limitations of this idea.</p> <h2 id="real-life-isnt-a-carefully-crafted-video-game">Real life isn’t a carefully crafted video game</h2> <p>Our daily challenges aren’t necessarily meaningful or valuable. Many struggles aren’t instructive—they’re random, painful occurrences delivering little personal growth or satisfaction.</p> <p>In these circumstances, reducing unnecessary trauma and harm isn’t “cheating”; it’s just common sense.</p> <h3 id="not-all-gain-requires-pain">Not all gain requires pain</h3> <p>And maybe I’ve overestimated the necessity of struggle and hardship for personal growth. Positive experiences like curiosity and creativity, can also shape who we become. Perhaps AI might help us learn and grow without unnecessarily painful detours.</p> <h3 id="but-some-gain-still-might">…but some gain still might?</h3> <p>Still, there’s a risk: if we delegate <em>every</em> challenging decision, we might lose the valuable tension that drives personal growth.</p> <p>There’s value in wrestling with uncertainty even when the AI reliably suggests <em>a</em> good path. That tension carries meaning—or at the very least feels very human.</p> <h2 id="local-maxima-trap">Local maxima trap</h2> <p><em>Further complicating things</em>, even if AI could perfectly optimize for our preferences, it might trap us in a ‘local maximum’—offering instant relief while stalling long-term growth. Picture an AI that keeps you in barely tolerable relationships or jobs, preventing the discomfort that often sparks transformative change.<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> In short, short-term comfort might lead to long-term stagnation, much like the marshmallow test suggests.</p> <h2 id="convenience-vs-agency">Convenience vs. Agency</h2> <p>All these thoughts bring me back to larger questions of personal agency. As AI improves, will relying on it drain my sense of autonomy? Will life lose some deep, intangible spark if I delegate too many important decisions?</p> <p>My current view: we will have to try and see. What comforts me a bit is reflecting on my life thus far. Despite thinking of myself as the <em>instant gratification monkey</em>, my life tells a different story—I actually go out of my comfort zone and do stuff despite the lure of The Algorithm.</p> <p>So I expect AI to become more powerful, more useful, and I also feel confident that I’ll notice if I start veering toward an unfulfilling, agency-lacking existence—and trust myself to course-correct.</p> <p>I’d love to hear your thoughts, and I’m curious how future-me will reflect on another year of closer reliance on AI.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>To be clear, today’s AIs carry <em>all the biases</em> inherited from training data; the hope is that they balance each other out. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>Current AIs are good at surface-level optimization but may fail to suggest difficult-in-the-moment but ultimately enriching decisions. Future models could potentially integrate secondary- and tertiary-level consequences, vectorize your preferences and <em>your whole psyche</em>, and ultimately be able to make decisions that are <em>just good for you</em>. But that is post-singularity AI, firmly in Speculationland. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </article> </div> </div> </div> <footer class="center"> <div class="measure"> <small> <!--Did <i>you</i> meditate <i>today</i>?--> <a href="https://www.lepekhin.com/feed.xml">RSS</a> </small> </div> </footer> <!-- Cloudflare Web Analytics --><script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "36d450e704ca4e97be531877d6bac8d7"}'></script><!-- End Cloudflare Web Analytics --> </body> </html>
